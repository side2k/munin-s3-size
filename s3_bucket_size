#!/usr/bin/python
from datetime import datetime
import subprocess

def get_file_list():
    process = subprocess.Popen(['s3cmd', 'la', '-r'], stdout=subprocess.PIPE)
    return process.stdout.readlines()
    
def parse_list(lines):
    result = []
    for line in lines:
        if not line.strip():
            continue
        fields = [field for field in line.strip().split(' ') if field]
        result.append({
            'timestamp':datetime.strptime('%s %s' % (fields[0], fields[1]),'%Y-%m-%d %H:%M'),
            'size':int(fields[2]),
            'path':fields[3]})
    return result
    
def get_bucket_name(path):
    (bucket_name,_,tail) = path.replace('s3://','',1).partition('/')
    return bucket_name
    
def aggregate_results(data):
    result = {}
    for element in data:
        bucket_name = get_bucket_name(element['path'])
        if bucket_name in result:
            result[bucket_name] += element['size']
        else:
            result[bucket_name] = element['size']
    return result
    

lines = get_file_list()
bucket_sizes = aggregate_results(parse_list(lines))
for bucket, size in bucket_sizes.iteritems():
    print '%s: %.3dM' % (bucket, size/1024/1024)